{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treetaggerwrapper    # https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motivation:\n",
    "# Brunet did not have lemmatization/word-sense-disambiguation libraries available to him; nonetheless, he \n",
    "# evidentally performed lemmatization in his analysis. This is clear from the tables he created to display\n",
    "# word counts, for example, 'chien' and 'chiens' are not listed separately. \n",
    "\n",
    "# Brunet did not explicitly state his lemmatization methodology, so in replication we are left we the task of choosing\n",
    "# our own. Automated lemmatization confers clear advantages in time and effort spent to produce coherent results.\n",
    "\n",
    "# 100% accuracy in this task is impossible, and likely not a desirable goal, considering we are not sure to what accuracy\n",
    "# Brunet lemmatized his work. Independent of the sophistication of the methods used for lemmatization \n",
    "# (it may be possible to be 'too' accurate compared to Brunet), \n",
    "# lemmatization should be considered one of many sources of departure from Brunet in this replication task.\n",
    "\n",
    "# Considering each text as a list of words, this function generates a list of tuples with Part of Speech and lemmas\n",
    "# corresponding to each word, such that lemmas can be directly compared and disambiguated with reference to their part\n",
    "# of speech if desired.\n",
    "#\n",
    "#\n",
    "#\n",
    "# Method Description:\n",
    "# Use TreeTaggerWrapper tool function to transform set of .txt documents \n",
    "# into a set of documents containing a list of tuples corresponding to the list of words in the original document.\n",
    "# Each tuple contains the original word, the Part-of-Speech tag, and the lemma of that word.\n",
    "# \n",
    "# Argument details:\n",
    "# exclude_nottags (bool) – dont generate NotTag for wrong size outputs. Default to False. (Set to True, no need to\n",
    "# generate noisy data)\n",
    "#\n",
    "\n",
    "\n",
    "def lemmatize_input_files(source_dir):\n",
    "    tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "    files = [f for f in glob.glob(source_dir + \"*.txt\")]\n",
    "    return {os.path.basename(f): treetaggerwrapper.make_tags(tagger.tag_file(f), exclude_nottags=True) for f in files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a utility function: rather than re-lemmatize the input text with every session, create a database of\n",
    "# lemmatized files that can be re-used so long as the input data does not change.\n",
    "\n",
    "def dump_data_to_files(output_dir, file_data_dict):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for filename, tags in file_data_dict.items():\n",
    "        file = open(output_dir + filename, \"wb\")\n",
    "        pickle.dump(tags, file)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# This function will create a new database of lemmatize text files corresponding to every book in the corpus\n",
    "# You will need to run this every time you add/remove books from the corpus.\n",
    "\n",
    "source_dir = \"../texts/txt/\"\n",
    "output_dir = \"../data\"\n",
    "\n",
    "file_data_dict = lemmatize_input_files(source_dir)\n",
    "dump_data_to_files(output_dir, file_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1935-Maxence Van Der Meersch-INVASION 14.txt', '1802-Chateaubriand-RENE.txt', '1913-Proust-DU CÔTÉ DE CHEZ SWANN.txt', '1883-Zola-AU BONHEUR DES DAMES.txt', '1913-Valery Larbaud-A.O. Barnabooth.txt', '1891-Huysmans-La bas.txt', '1922-Martin Du Gard-LES THIBAULT.txt', '1916-Colette-LA PAIX CHEZ LES BATES.txt', '1894-Jules Renard-Poil de Carotte.txt', '1902-Colette-Claudine a l’École.txt', '1929-Colette-Sido.txt', '1883-Maupassant-Contes et Nouvelles.txt', '1929-Jean Giono-Un de Baumugnes.txt', '1904-Colette-Dialogues De Bêtes.txt', '1932-Celine-VOYAGE AU BOUT DE LA NUIT .txt', '1807-Chateaubriand-Les Aventures du dernier Abencerage.txt', '1801-Chateaubriand-ATALA.txt', '1922-Colette-LA MAISON DE CLAUDINE.txt', '1874-Zola-LA CONQUETE DE PLASSANS.txt', '1928-Andre Breton-Nadja.txt', \"1891-Zola-L'argent.txt\", '1913-Pergaud-LE ROMAN DE MIRAUT.txt', '1955-Françoise Sagan-Bonjour tristesse.txt', \"1949-Jean Paul Sartre-La mort dans l'ame.txt\", '1910-Pergaud-DE GOUPIL À MARGOT.txt', '1892-Zola-LE DEBACLE.txt', '1921-Giraudoux-Suzanne et le Pacifique.txt', '1954-Simone de Beauvoir-Les mandarins .txt', '1.Source.txt', '1878-Loti-Le Mariage de Loti.txt', '1890-Zola-LA BETE HUMANINE.txt', '1914-Colette-LES HEURES LONGUES.txt', '1929-Jean Giono-COLLINE.txt', '1908-Proust-A LA RECHERCHE DU TEMPS PERDU.txt', '1910-Vogüé-LES MORTS QUI PARLENT.txt', \"1906-Claude Farrère-L'HOMME QUI ASSASSINA.txt\", '1928-Colette-La Naissancue Du Jour.txt', '1936-Celine-MORT À CRÉDIT.txt', '1918-Giraudoux-simon le pathetique.txt', '1880-Zola-NANA.txt', '1925-Andre Gide-Les Faux Monnayeurs.txt', '1920-Colette-CHÉRI.txt', '1933-Colette-LA CHATTE.txt', \"1875-Jules Verne-L'ÎLE MYSTÉRIEUSE.txt\", '1966-Bernanos-Nouvelle histoire de Mouchette.txt', '1876-Gobineau Joseph-Nouvelles Asiatiques.txt', '1912-Pergaud-LA GUERRE DES BOUTONS.txt', '1940-Joseph Malegue-Augustin ou le maitre est la .txt']\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
